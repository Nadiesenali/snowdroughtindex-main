{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaSR SWE File Combination Workflow\n",
    "\n",
    "This notebook demonstrates how to combine NetCDF files from the CaSR SWE dataset using the `combine_casr_swe_files.py` script. The CaSR dataset contains files organized by variable types, spatial regions, and time periods that can be combined in different ways:\n",
    "\n",
    "1. **Temporal combination**: Combine files across time periods\n",
    "2. **Spatial combination**: Combine files across spatial regions  \n",
    "3. **Full combination**: Combine both temporal and spatial dimensions\n",
    "\n",
    "The CaSR SWE dataset includes:\n",
    "- **Variable types**: A_PR24_SFC (precipitation) and P_SWE_LAND (snow water equivalent)\n",
    "- **Spatial regions**: Different rlon/rlat coordinate ranges\n",
    "- **Time periods**: 4-year chunks from 1980-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "**Note**: If you encounter NumPy compatibility errors, please run one of the following commands in your terminal before running this notebook:\n",
    "\n",
    "**Option 1 (Recommended)**: Install from requirements file\n",
    "```bash\n",
    "pip install -r requirements_notebook.txt\n",
    "```\n",
    "\n",
    "**Option 2**: Manual installation with compatible versions\n",
    "```bash\n",
    "pip install \"numpy<2\" xarray pandas matplotlib netcdf4\n",
    "```\n",
    "\n",
    "**Option 3**: Using conda\n",
    "```bash\n",
    "conda install numpy=1.26 xarray pandas matplotlib netcdf4\n",
    "```\n",
    "\n",
    "**Option 4**: Create a new environment with compatible versions\n",
    "```bash\n",
    "conda create -n snowdrought python=3.9 numpy=1.26 xarray pandas matplotlib netcdf4 jupyter\n",
    "conda activate snowdrought\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NumPy compatibility issues\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='numpy')\n",
    "\n",
    "# Import required packages\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Handle NumPy compatibility\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"NumPy version: {np.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"NumPy import error: {e}\")\n",
    "    print(\"Please install NumPy: pip install numpy\")\n",
    "\n",
    "# Import data science packages with error handling\n",
    "try:\n",
    "    import xarray as xr\n",
    "    print(f\"xarray version: {xr.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"xarray import error: {e}\")\n",
    "    print(\"If you encounter NumPy compatibility issues, try:\")\n",
    "    print(\"  pip install 'numpy<2' xarray pandas matplotlib\")\n",
    "    print(\"  or\")\n",
    "    print(\"  conda install numpy=1.26 xarray pandas matplotlib\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(f\"pandas version: {pd.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"pandas import error: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(f\"matplotlib version: {plt.matplotlib.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"matplotlib import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Add the project root to Python path to import the combine script\n",
    "project_root = Path().cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import the CaSR file combiner\n",
    "try:\n",
    "    from combine_casr_swe_files import CaSRFileCombiner\n",
    "    print(\"Successfully imported CaSRFileCombiner\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing CaSRFileCombiner: {e}\")\n",
    "    print(\"Make sure combine_casr_swe_files.py is in the project root directory\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the input and output directories for your CaSR SWE data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths - modify these paths according to your data location\n",
    "input_dir = r\"data/input_data/CaSR_SWE\"  # Directory containing CaSR NetCDF files\n",
    "output_dir = r\"data/output_data/combined_casr\"  # Directory for combined output files\n",
    "\n",
    "# Create absolute paths\n",
    "input_path = project_root / input_dir\n",
    "output_path = project_root / output_dir\n",
    "\n",
    "print(f\"Input directory: {input_path}\")\n",
    "print(f\"Output directory: {output_path}\")\n",
    "print(f\"Input directory exists: {input_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the CaSR File Combiner\n",
    "\n",
    "Create an instance of the `CaSRFileCombiner` class with your input and output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the file combiner\n",
    "combiner = CaSRFileCombiner(input_dir=str(input_path), output_dir=str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset Information\n",
    "\n",
    "Before combining files, let's examine what data is available in the input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the available datasets\n",
    "combiner.get_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine File Groups\n",
    "\n",
    "Let's look at how the files are grouped by variable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file groups\n",
    "file_groups = combiner.get_file_groups()\n",
    "\n",
    "print(\"Available file groups:\")\n",
    "for group_name, files in file_groups.items():\n",
    "    print(f\"\\n{group_name}: {len(files)} files\")\n",
    "    \n",
    "    # Show first few filenames as examples\n",
    "    for i, file_path in enumerate(files[:3]):\n",
    "        filename = Path(file_path).name\n",
    "        print(f\"  {i+1}. {filename}\")\n",
    "    \n",
    "    if len(files) > 3:\n",
    "        print(f\"  ... and {len(files) - 3} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Parse Individual Filenames\n",
    "\n",
    "Let's examine how the filename parsing works for understanding the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample file and parse its filename\n",
    "if file_groups:\n",
    "    # Get the first file from the first group\n",
    "    first_group = list(file_groups.keys())[0]\n",
    "    sample_file = file_groups[first_group][0]\n",
    "    sample_filename = Path(sample_file).name\n",
    "    \n",
    "    print(f\"Sample filename: {sample_filename}\")\n",
    "    \n",
    "    # Parse the filename\n",
    "    parsed_info = combiner.parse_filename(sample_filename)\n",
    "    \n",
    "    print(\"\\nParsed information:\")\n",
    "    for key, value in parsed_info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No files found in the input directory. Please check your input path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Options\n",
    "\n",
    "Now let's demonstrate the different ways to combine the CaSR files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Temporal Combination Only\n",
    "\n",
    "Combine files across time periods while keeping spatial regions separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal combination only\n",
    "print(\"Performing temporal combination (keeping spatial regions separate)...\")\n",
    "combiner.combine_by_variable(combine_spatial=False, combine_temporal=True)\n",
    "print(\"Temporal combination completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Spatial Combination Only\n",
    "\n",
    "Combine files across spatial regions while keeping time periods separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial combination only\n",
    "print(\"Performing spatial combination (keeping time periods separate)...\")\n",
    "combiner.combine_by_variable(combine_spatial=True, combine_temporal=False)\n",
    "print(\"Spatial combination completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Full Combination\n",
    "\n",
    "Combine files across both spatial and temporal dimensions to create complete datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full combination (both spatial and temporal)\n",
    "print(\"Performing full combination (both spatial and temporal)...\")\n",
    "combiner.combine_by_variable(combine_spatial=True, combine_temporal=True)\n",
    "print(\"Full combination completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Combined Output Files\n",
    "\n",
    "Let's check what files were created in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List output files\n",
    "output_files = list(output_path.glob('*.nc'))\n",
    "\n",
    "print(f\"Combined files created in {output_path}:\")\n",
    "print(f\"Total files: {len(output_files)}\\n\")\n",
    "\n",
    "for i, file_path in enumerate(output_files, 1):\n",
    "    file_size = file_path.stat().st_size / (1024**2)  # Size in MB\n",
    "    print(f\"{i}. {file_path.name} ({file_size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Examine a Combined Dataset\n",
    "\n",
    "Let's load one of the combined files to examine its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a combined dataset for examination\n",
    "if output_files:\n",
    "    # Select the first combined file\n",
    "    sample_combined_file = output_files[0]\n",
    "    print(f\"Loading: {sample_combined_file.name}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    ds_combined = xr.open_dataset(sample_combined_file)\n",
    "    \n",
    "    print(\"\\nDataset information:\")\n",
    "    print(f\"Dimensions: {dict(ds_combined.sizes)}\")\n",
    "    print(f\"Variables: {list(ds_combined.data_vars.keys())}\")\n",
    "    print(f\"Coordinates: {list(ds_combined.coords.keys())}\")\n",
    "    \n",
    "    # Show time range if time dimension exists\n",
    "    if 'time' in ds_combined.dims:\n",
    "        time_start = pd.to_datetime(ds_combined.time.min().values)\n",
    "        time_end = pd.to_datetime(ds_combined.time.max().values)\n",
    "        print(f\"Time range: {time_start.strftime('%Y-%m-%d')} to {time_end.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Show dataset attributes\n",
    "    print(\"\\nDataset attributes:\")\n",
    "    for attr, value in ds_combined.attrs.items():\n",
    "        if isinstance(value, list) and len(value) > 5:\n",
    "            print(f\"  {attr}: [{len(value)} files combined]\")\n",
    "        else:\n",
    "            print(f\"  {attr}: {value}\")\n",
    "    \n",
    "    # Close the dataset\n",
    "    ds_combined.close()\n",
    "else:\n",
    "    print(\"No combined files found. Please run the combination steps first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Combined Data\n",
    "\n",
    "Let's create a simple visualization of the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple visualization of the combined data\n",
    "if output_files:\n",
    "    # Load a combined SWE dataset if available\n",
    "    swe_files = [f for f in output_files if 'SWE' in f.name]\n",
    "    \n",
    "    if swe_files:\n",
    "        ds_swe = xr.open_dataset(swe_files[0])\n",
    "        \n",
    "        # Get the SWE variable name\n",
    "        swe_var = None\n",
    "        for var in ds_swe.data_vars:\n",
    "            if 'SWE' in var:\n",
    "                swe_var = var\n",
    "                break\n",
    "        \n",
    "        if swe_var and 'time' in ds_swe.dims:\n",
    "            # Plot time series of mean SWE\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "            \n",
    "            # Time series plot\n",
    "            swe_mean = ds_swe[swe_var].mean(dim=['rlon', 'rlat'])\n",
    "            swe_mean.plot(ax=ax1)\n",
    "            ax1.set_title(f'Mean SWE Time Series - {swe_files[0].name}')\n",
    "            ax1.set_ylabel('SWE (mm)')\n",
    "            \n",
    "            # Spatial plot for a sample time\n",
    "            if len(ds_swe.time) > 0:\n",
    "                sample_time = ds_swe.time[len(ds_swe.time)//2]  # Middle time point\n",
    "                swe_spatial = ds_swe[swe_var].sel(time=sample_time)\n",
    "                \n",
    "                im = swe_spatial.plot(ax=ax2, cmap='Blues')\n",
    "                ax2.set_title(f'SWE Spatial Distribution - {pd.to_datetime(sample_time.values).strftime(\"%Y-%m-%d\")}')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_output_dir = project_root / \"data\" / \"output_plots\"\n",
    "            plot_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            plt.savefig(plot_output_dir / 'combined_casr_swe_overview.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            ds_swe.close()\n",
    "        else:\n",
    "            print(\"No suitable SWE variable or time dimension found for visualization.\")\n",
    "    else:\n",
    "        print(\"No SWE files found in the combined outputs.\")\n",
    "else:\n",
    "    print(\"No combined files available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Combination Example\n",
    "\n",
    "Here's an example of how to perform custom combinations using the individual methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Custom temporal combination for a specific variable and spatial region\n",
    "file_groups = combiner.get_file_groups()\n",
    "\n",
    "if file_groups:\n",
    "    # Select files for a specific variable (e.g., SWE)\n",
    "    swe_group = None\n",
    "    for group_name, files in file_groups.items():\n",
    "        if 'SWE' in group_name:\n",
    "            swe_group = group_name\n",
    "            break\n",
    "    \n",
    "    if swe_group:\n",
    "        print(f\"Working with group: {swe_group}\")\n",
    "        \n",
    "        # Group files by spatial region\n",
    "        spatial_groups = {}\n",
    "        for file_path in file_groups[swe_group]:\n",
    "            parsed = combiner.parse_filename(Path(file_path).name)\n",
    "            if parsed:\n",
    "                spatial_key = f\"{parsed['rlon_range']}_{parsed['rlat_range']}\"\n",
    "                if spatial_key not in spatial_groups:\n",
    "                    spatial_groups[spatial_key] = []\n",
    "                spatial_groups[spatial_key].append(file_path)\n",
    "        \n",
    "        print(f\"\\nFound {len(spatial_groups)} spatial regions:\")\n",
    "        for spatial_key, files in spatial_groups.items():\n",
    "            print(f\"  {spatial_key}: {len(files)} files\")\n",
    "        \n",
    "        # Combine temporally for the first spatial region as an example\n",
    "        if spatial_groups:\n",
    "            first_spatial_key = list(spatial_groups.keys())[0]\n",
    "            first_spatial_files = spatial_groups[first_spatial_key]\n",
    "            \n",
    "            print(f\"\\nCombining {len(first_spatial_files)} files for region {first_spatial_key}...\")\n",
    "            \n",
    "            custom_output_filename = f\"CaSR_v3.1_{swe_group}_{first_spatial_key}_custom_temporal.nc\"\n",
    "            combiner.combine_temporal(first_spatial_files, custom_output_filename)\n",
    "            \n",
    "            print(f\"Custom combination completed: {custom_output_filename}\")\n",
    "    else:\n",
    "        print(\"No SWE group found in the file groups.\")\n",
    "else:\n",
    "    print(\"No file groups available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated how to use the `CaSRFileCombiner` class to combine NetCDF files from the CaSR SWE dataset. The key capabilities include:\n",
    "\n",
    "1. **Dataset exploration**: Understanding the structure and organization of CaSR files\n",
    "2. **Temporal combination**: Combining files across time periods\n",
    "3. **Spatial combination**: Combining files across spatial regions\n",
    "4. **Full combination**: Creating complete datasets with both spatial and temporal coverage\n",
    "5. **Custom combinations**: Flexible combination strategies for specific needs\n",
    "\n",
    "### Key Functions Used:\n",
    "- `CaSRFileCombiner()`: Main class for file combination\n",
    "- `get_dataset_info()`: Explore available data\n",
    "- `get_file_groups()`: Group files by variable type\n",
    "- `parse_filename()`: Extract metadata from filenames\n",
    "- `combine_by_variable()`: Automated combination by variable type\n",
    "- `combine_temporal()`: Manual temporal combination\n",
    "- `combine_spatial_regions()`: Manual spatial combination\n",
    "\n",
    "### Next Steps:\n",
    "1. Use the combined datasets in your snow drought analysis workflows\n",
    "2. Apply the combined data to specific study regions or basins\n",
    "3. Integrate with other notebooks in this workflow series\n",
    "4. Customize combination strategies based on your research needs\n",
    "\n",
    "The combined files are saved in the output directory and can be used directly with xarray and other analysis tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
