{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaSR SWE File Combination Workflow\n",
    "\n",
    "This notebook demonstrates how to combine NetCDF files from the CaSR SWE dataset using the `combine_casr_swe_files.py` script. The CaSR dataset contains files organized by variable types, spatial regions, and time periods that can be combined in different ways:\n",
    "\n",
    "1. **Temporal combination**: Combine files across time periods\n",
    "2. **Spatial combination**: Combine files across spatial regions  \n",
    "3. **Full combination**: Combine both temporal and spatial dimensions\n",
    "\n",
    "The CaSR SWE dataset includes:\n",
    "- **Variable types**: A_PR24_SFC (precipitation) and P_SWE_LAND (snow water equivalent)\n",
    "- **Spatial regions**: Different rlon/rlat coordinate ranges\n",
    "- **Time periods**: 4-year chunks from 1980-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "**Note**: If you encounter NumPy compatibility errors, please run one of the following commands in your terminal before running this notebook:\n",
    "\n",
    "**Option 1 (Recommended)**: Install from requirements file\n",
    "```bash\n",
    "pip install -r requirements_notebook.txt\n",
    "```\n",
    "\n",
    "**Option 2**: Manual installation with compatible versions\n",
    "```bash\n",
    "pip install \"numpy<2\" xarray pandas matplotlib netcdf4\n",
    "```\n",
    "\n",
    "**Option 3**: Using conda\n",
    "```bash\n",
    "conda install numpy=1.26 xarray pandas matplotlib netcdf4\n",
    "```\n",
    "\n",
    "**Option 4**: Create a new environment with compatible versions\n",
    "```bash\n",
    "conda create -n snowdrought python=3.9 numpy=1.26 xarray pandas matplotlib netcdf4 jupyter\n",
    "conda activate snowdrought\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NumPy compatibility issues\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='numpy')\n",
    "\n",
    "# Import required packages\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Handle NumPy compatibility\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"NumPy version: {np.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"NumPy import error: {e}\")\n",
    "    print(\"Please install NumPy: pip install numpy\")\n",
    "\n",
    "# Import data science packages with error handling\n",
    "try:\n",
    "    import xarray as xr\n",
    "    print(f\"xarray version: {xr.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"xarray import error: {e}\")\n",
    "    print(\"If you encounter NumPy compatibility issues, try:\")\n",
    "    print(\"  pip install 'numpy<2' xarray pandas matplotlib\")\n",
    "    print(\"  or\")\n",
    "    print(\"  conda install numpy=1.26 xarray pandas matplotlib\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(f\"pandas version: {pd.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"pandas import error: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(f\"matplotlib version: {plt.matplotlib.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"matplotlib import error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Add the project root to Python path to import the combine script\n",
    "project_root = Path().cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import the CaSR file combiner\n",
    "try:\n",
    "    from combine_casr_swe_files import CaSRFileCombiner\n",
    "    print(\"Successfully imported CaSRFileCombiner\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing CaSRFileCombiner: {e}\")\n",
    "    print(\"Make sure combine_casr_swe_files.py is in the project root directory\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the input and output directories for your CaSR SWE data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths - modify these paths according to your data location\n",
    "input_dir = r\"data/input_data/CaSR_SWE\"  # Directory containing CaSR NetCDF files\n",
    "output_dir = r\"data/output_data/combined_casr\"  # Directory for combined output files\n",
    "\n",
    "# Create absolute paths\n",
    "input_path = project_root / input_dir\n",
    "output_path = project_root / output_dir\n",
    "\n",
    "print(f\"Input directory: {input_path}\")\n",
    "print(f\"Output directory: {output_path}\")\n",
    "print(f\"Input directory exists: {input_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the CaSR File Combiner\n",
    "\n",
    "Create an instance of the `CaSRFileCombiner` class with your input and output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the file combiner\n",
    "combiner = CaSRFileCombiner(input_dir=str(input_path), output_dir=str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset Information\n",
    "\n",
    "Before combining files, let's examine what data is available in the input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the available datasets\n",
    "combiner.get_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine File Groups\n",
    "\n",
    "Let's look at how the files are grouped by variable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file groups\n",
    "file_groups = combiner.get_file_groups()\n",
    "\n",
    "print(\"Available file groups:\")\n",
    "for group_name, files in file_groups.items():\n",
    "    print(f\"\\n{group_name}: {len(files)} files\")\n",
    "    \n",
    "    # Show first few filenames as examples\n",
    "    for i, file_path in enumerate(files[:3]):\n",
    "        filename = Path(file_path).name\n",
    "        print(f\"  {i+1}. {filename}\")\n",
    "    \n",
    "    if len(files) > 3:\n",
    "        print(f\"  ... and {len(files) - 3} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Parse Individual Filenames\n",
    "\n",
    "Let's examine how the filename parsing works for understanding the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample file and parse its filename\n",
    "if file_groups:\n",
    "    # Get the first file from the first group\n",
    "    first_group = list(file_groups.keys())[0]\n",
    "    sample_file = file_groups[first_group][0]\n",
    "    sample_filename = Path(sample_file).name\n",
    "    \n",
    "    print(f\"Sample filename: {sample_filename}\")\n",
    "    \n",
    "    # Parse the filename\n",
    "    parsed_info = combiner.parse_filename(sample_filename)\n",
    "    \n",
    "    print(\"\\nParsed information:\")\n",
    "    for key, value in parsed_info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No files found in the input directory. Please check your input path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Options\n",
    "\n",
    "Now let's demonstrate the different ways to combine the CaSR files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Temporal Combination Only\n",
    "\n",
    "Combine files across time periods while keeping spatial regions separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal combination only\n",
    "print(\"Performing temporal combination (keeping spatial regions separate)...\")\n",
    "combiner.combine_by_variable(combine_spatial=False, combine_temporal=True)\n",
    "print(\"Temporal combination completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Spatial Combination Only\n",
    "\n",
    "Combine files across spatial regions while keeping time periods separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial combination only\n",
    "print(\"Performing spatial combination (keeping time periods separate)...\")\n",
    "combiner.combine_by_variable(combine_spatial=True, combine_temporal=False)\n",
    "print(\"Spatial combination completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Full Combination\n",
    "\n",
    "Combine files across both spatial and temporal dimensions to create complete datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full combination (both spatial and temporal)\n",
    "print(\"Performing full combination (both spatial and temporal)...\")\n",
    "combiner.combine_by_variable(combine_spatial=True, combine_temporal=True)\n",
    "print(\"Full combination completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Combined Output Files\n",
    "\n",
    "Let's check what files were created in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List output files\n",
    "output_files = list(output_path.glob('*.nc'))\n",
    "\n",
    "print(f\"Combined files created in {output_path}:\")\n",
    "print(f\"Total files: {len(output_files)}\\n\")\n",
    "\n",
    "for i, file_path in enumerate(output_files, 1):\n",
    "    file_size = file_path.stat().st_size / (1024**2)  # Size in MB\n",
    "    print(f\"{i}. {file_path.name} ({file_size:.1f} MB)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
