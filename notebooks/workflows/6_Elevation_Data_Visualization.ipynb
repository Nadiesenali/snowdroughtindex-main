{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevation Data Visualization Workflow\n",
    "\n",
    "This notebook visualizes elevation data from:\n",
    "- **CSV Data**: `data/output_data/filtered_elevation/filtered_elevation_data.csv` - Filtered precipitation and SWE data with elevation information\n",
    "- **Shapefile**: `data/input_data/Elevation/Bow_elevation_combined.shp` - Elevation classification polygons\n",
    "\n",
    "## Workflow Overview\n",
    "1. **Data Loading & Exploration** - Load and examine both datasets\n",
    "2. **Spatial Visualizations** - Maps showing elevation classes and data distribution\n",
    "3. **Statistical Analysis** - Relationships between elevation, precipitation, and SWE\n",
    "4. **Temporal Patterns** - Time series analysis by elevation\n",
    "5. **Advanced Visualizations** - 3D plots and interactive dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# %pip install geopandas matplotlib seaborn plotly rasterio\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"✅ Imports completed successfully\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define File Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "csv_file_path = Path(\"../../data/output_data/filtered_elevation/filtered_elevation_data.csv\")\n",
    "shapefile_path = Path(\"../../data/input_data/Elevation/Bow_elevation_combined.shp\")\n",
    "output_plots_dir = Path(\"../../data/output_plots\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration for data loading\n",
    "CHUNK_SIZE = 50000  # Number of rows to load at a time for large CSV\n",
    "SAMPLE_SIZE = None  # Set to a number to sample data for testing, None for all data\n",
    "RANDOM_STATE = 42   # For reproducible sampling\n",
    "\n",
    "# Check if files exist\n",
    "print(\"File existence check:\")\n",
    "print(f\"CSV file: {csv_file_path.exists()} - {csv_file_path}\")\n",
    "print(f\"Shapefile: {shapefile_path.exists()} - {shapefile_path}\")\n",
    "print(f\"Output directory: {output_plots_dir.exists()} - {output_plots_dir}\")\n",
    "\n",
    "if csv_file_path.exists():\n",
    "    file_size_mb = csv_file_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"CSV file size: {file_size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Shapefile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shapefile\n",
    "print(\"Loading shapefile...\")\n",
    "try:\n",
    "    elevation_gdf = gpd.read_file(shapefile_path)\n",
    "    print(f\"✅ Shapefile loaded successfully\")\n",
    "    print(f\"Shape: {elevation_gdf.shape}\")\n",
    "    print(f\"CRS: {elevation_gdf.crs}\")\n",
    "    print(f\"\\nColumns: {list(elevation_gdf.columns)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(elevation_gdf.head())\n",
    "    \n",
    "    # Basic statistics for numeric columns\n",
    "    numeric_cols = elevation_gdf.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"\\nNumeric column statistics:\")\n",
    "        display(elevation_gdf[numeric_cols].describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading shapefile: {e}\")\n",
    "    elevation_gdf = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Explore CSV Data (Memory Efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_efficiently(file_path, chunk_size=CHUNK_SIZE, sample_size=SAMPLE_SIZE):\n",
    "    \"\"\"\n",
    "    Load large CSV file efficiently using chunking.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : Path\n",
    "        Path to CSV file\n",
    "    chunk_size : int\n",
    "        Size of chunks to load\n",
    "    sample_size : int or None\n",
    "        Number of rows to sample, None for all data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Loaded data\n",
    "    \"\"\"\n",
    "    print(f\"Loading CSV data from {file_path.name}...\")\n",
    "    \n",
    "    try:\n",
    "        # First, peek at the file to understand structure\n",
    "        sample_df = pd.read_csv(file_path, nrows=5)\n",
    "        print(f\"Columns found: {list(sample_df.columns)}\")\n",
    "        \n",
    "        if sample_size:\n",
    "            print(f\"Sampling {sample_size:,} rows...\")\n",
    "            # For sampling, we'll load in chunks and sample\n",
    "            chunks = []\n",
    "            total_loaded = 0\n",
    "            \n",
    "            for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "                # Convert time column if it exists\n",
    "                if 'time' in chunk.columns:\n",
    "                    chunk['time'] = pd.to_datetime(chunk['time'])\n",
    "                \n",
    "                chunks.append(chunk)\n",
    "                total_loaded += len(chunk)\n",
    "                \n",
    "                if total_loaded >= sample_size * 2:  # Load extra for better sampling\n",
    "                    break\n",
    "            \n",
    "            # Combine chunks and sample\n",
    "            df = pd.concat(chunks, ignore_index=True)\n",
    "            if len(df) > sample_size:\n",
    "                df = df.sample(n=sample_size, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "        \n",
    "        else:\n",
    "            print(\"Loading all data in chunks...\")\n",
    "            chunks = []\n",
    "            \n",
    "            for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "                # Convert time column if it exists\n",
    "                if 'time' in chunk.columns:\n",
    "                    chunk['time'] = pd.to_datetime(chunk['time'])\n",
    "                \n",
    "                chunks.append(chunk)\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"  Loaded {(i + 1) * chunk_size:,} rows...\")\n",
    "            \n",
    "            df = pd.concat(chunks, ignore_index=True)\n",
    "        \n",
    "        print(f\"✅ CSV data loaded successfully\")\n",
    "        print(f\"Final shape: {df.shape}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the CSV data\n",
    "elevation_df = load_csv_efficiently(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the CSV data structure\n",
    "if elevation_df is not None:\n",
    "    print(\"CSV Data Exploration:\")\n",
    "    print(f\"Shape: {elevation_df.shape}\")\n",
    "    print(f\"Memory usage: {elevation_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    print(\"\\nColumn information:\")\n",
    "    for col in elevation_df.columns:\n",
    "        dtype = elevation_df[col].dtype\n",
    "        null_count = elevation_df[col].isnull().sum()\n",
    "        null_pct = (null_count / len(elevation_df)) * 100\n",
    "        print(f\"  {col}: {dtype}, {null_count:,} nulls ({null_pct:.1f}%)\")\n",
    "    \n",
    "    # Identify key columns\n",
    "    precip_cols = [col for col in elevation_df.columns if 'PR24' in col or 'precip' in col.lower()]\n",
    "    swe_cols = [col for col in elevation_df.columns if 'SWE' in col or 'swe' in col.lower()]\n",
    "    elev_cols = [col for col in elevation_df.columns if 'elevation' in col.lower()]\n",
    "    coord_cols = [col for col in elevation_df.columns if any(x in col.lower() for x in ['lat', 'lon', 'x', 'y'])]\n",
    "    \n",
    "    print(f\"\\nKey column groups:\")\n",
    "    print(f\"  Precipitation columns: {precip_cols}\")\n",
    "    print(f\"  SWE columns: {swe_cols}\")\n",
    "    print(f\"  Elevation columns: {elev_cols}\")\n",
    "    print(f\"  Coordinate columns: {coord_cols}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(elevation_df.head())\n",
    "    \n",
    "    # Basic statistics for key numeric columns\n",
    "    key_cols = precip_cols + swe_cols + elev_cols\n",
    "    if key_cols:\n",
    "        print(\"\\nKey column statistics:\")\n",
    "        display(elevation_df[key_cols].describe())\n",
    "else:\n",
    "    print(\"❌ CSV data not available for exploration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic Spatial Visualization - Elevation Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot elevation classes from shapefile\n",
    "if elevation_gdf is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Basic elevation map\n",
    "    elevation_gdf.plot(ax=axes[0], edgecolor='black', linewidth=0.5, alpha=0.7)\n",
    "    axes[0].set_title('Elevation Polygons - Basic View', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Plot 2: Colored by elevation class if available\n",
    "    if 'elev_class' in elevation_gdf.columns:\n",
    "        # Plot by elevation class\n",
    "        elevation_gdf.plot(column='elev_class', ax=axes[1], legend=True, \n",
    "                          cmap='terrain', edgecolor='black', linewidth=0.5)\n",
    "        axes[1].set_title('Elevation Classes', fontsize=14, fontweight='bold')\n",
    "    elif 'mean' in elevation_gdf.columns:\n",
    "        # Plot by mean elevation\n",
    "        elevation_gdf.plot(column='mean', ax=axes[1], legend=True, \n",
    "                          cmap='terrain', edgecolor='black', linewidth=0.5)\n",
    "        axes[1].set_title('Mean Elevation', fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        # Just plot basic map\n",
    "        elevation_gdf.plot(ax=axes[1], edgecolor='black', linewidth=0.5, alpha=0.7)\n",
    "        axes[1].set_title('Elevation Polygons', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_plots_dir / 'elevation_shapefile_overview.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✅ Elevation shapefile visualization saved to {output_plots_dir / 'elevation_shapefile_overview.png'}\")\n",
    "else:\n",
    "    print(\"❌ Shapefile not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Point Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spatial distribution of data points from CSV\n",
    "if elevation_df is not None and coord_cols:\n",
    "    # Identify longitude and latitude columns with prioritization\n",
    "    lon_col = None\n",
    "    lat_col = None\n",
    "    \n",
    "    # Priority 1: grid_lon and grid_lat (most accurate for spatial analysis)\n",
    "    if 'grid_lon' in elevation_df.columns and 'grid_lat' in elevation_df.columns:\n",
    "        lon_col = 'grid_lon'\n",
    "        lat_col = 'grid_lat'\n",
    "        print(\"✅ Using prioritized grid coordinates: grid_lon, grid_lat\")\n",
    "    # Priority 2: original_lon and original_lat\n",
    "    elif 'original_lon' in elevation_df.columns and 'original_lat' in elevation_df.columns:\n",
    "        lon_col = 'original_lon'\n",
    "        lat_col = 'original_lat'\n",
    "        print(\"Using original coordinates: original_lon, original_lat\")\n",
    "    # Priority 3: flexible detection for other coordinate naming conventions\n",
    "    else:\n",
    "        for col in coord_cols:\n",
    "            if 'lon' in col.lower() and lon_col is None:\n",
    "                lon_col = col\n",
    "            elif 'lat' in col.lower() and lat_col is None:\n",
    "                lat_col = col\n",
    "        if lon_col and lat_col:\n",
    "            print(f\"Using detected coordinates: {lon_col}, {lat_col}\")\n",
    "    \n",
    "    if lon_col and lat_col:\n",
    "        print(f\"Final coordinate selection: {lon_col}, {lat_col}\")\n",
    "        \n",
    "        # Create a sample for plotting if data is too large\n",
    "        plot_df = elevation_df\n",
    "        if len(elevation_df) > 10000:\n",
    "            plot_df = elevation_df.sample(n=10000, random_state=RANDOM_STATE)\n",
    "            print(f\"Sampling {len(plot_df):,} points for visualization\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Plot 1: Point distribution\n",
    "        axes[0].scatter(plot_df[lon_col], plot_df[lat_col], \n",
    "                       alpha=0.5, s=1, c='blue')\n",
    "        axes[0].set_xlabel('Longitude')\n",
    "        axes[0].set_ylabel('Latitude')\n",
    "        axes[0].set_title(f'Data Point Distribution\\n({len(plot_df):,} points using {lon_col}, {lat_col})', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Point distribution with elevation color if available\n",
    "        if elev_cols:\n",
    "            elev_col = elev_cols[0]  # Use first elevation column\n",
    "            scatter = axes[1].scatter(plot_df[lon_col], plot_df[lat_col], \n",
    "                                    c=plot_df[elev_col], cmap='terrain', \n",
    "                                    alpha=0.6, s=2)\n",
    "            plt.colorbar(scatter, ax=axes[1], label='Elevation (m)')\n",
    "            axes[1].set_title(f'Data Points Colored by Elevation\\n({elev_col})', \n",
    "                             fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            axes[1].scatter(plot_df[lon_col], plot_df[lat_col], \n",
    "                           alpha=0.5, s=1, c='red')\n",
    "            axes[1].set_title('Data Point Distribution', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        axes[1].set_xlabel('Longitude')\n",
    "        axes[1].set_ylabel('Latitude')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_plots_dir / 'data_point_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✅ Data point distribution saved to {output_plots_dir / 'data_point_distribution.png'}\")\n",
    "    else:\n",
    "        print(\"❌ Could not identify longitude and latitude columns\")\n",
    "else:\n",
    "    print(\"❌ CSV data or coordinate columns not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combined Spatial Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine shapefile and point data in one plot\n",
    "if elevation_gdf is not None and elevation_df is not None and lon_col and lat_col:\n",
    "    # Create a sample for plotting\n",
    "    plot_df = elevation_df\n",
    "    if len(elevation_df) > 5000:\n",
    "        plot_df = elevation_df.sample(n=5000, random_state=RANDOM_STATE)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Plot elevation polygons\n",
    "    if 'elev_class' in elevation_gdf.columns:\n",
    "        elevation_gdf.plot(column='elev_class', ax=ax, legend=True, \n",
    "                          cmap='terrain', edgecolor='black', linewidth=0.5, alpha=0.7)\n",
    "    elif 'mean' in elevation_gdf.columns:\n",
    "        elevation_gdf.plot(column='mean', ax=ax, legend=True, \n",
    "                          cmap='terrain', edgecolor='black', linewidth=0.5, alpha=0.7)\n",
    "    else:\n",
    "        elevation_gdf.plot(ax=ax, edgecolor='black', linewidth=0.5, alpha=0.7, color='lightgray')\n",
    "    \n",
    "    # Overlay data points\n",
    "    ax.scatter(plot_df[lon_col], plot_df[lat_col], \n",
    "              c='red', s=0.5, alpha=0.6, label=f'Data Points (n={len(plot_df):,})')\n",
    "    \n",
    "    ax.set_title(f'Elevation Classes with Data Point Locations\\nUsing {lon_col}, {lat_col}', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_plots_dir / 'combined_elevation_points.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✅ Combined visualization saved to {output_plots_dir / 'combined_elevation_points.png'}\")\n",
    "else:\n",
    "    print(\"❌ Cannot create combined visualization - missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Statistical Analysis - Elevation vs. Precipitation/SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationships between elevation and climate variables\n",
    "if elevation_df is not None and elev_cols and (precip_cols or swe_cols):\n",
    "    # Use the first available columns\n",
    "    elev_col = elev_cols[0]\n",
    "    \n",
    "    # Create elevation bins for analysis\n",
    "    elevation_df['elevation_bin'] = pd.cut(elevation_df[elev_col], bins=10, precision=0)\n",
    "    \n",
    "    # Set up the plotting area\n",
    "    n_plots = len(precip_cols) + len(swe_cols)\n",
    "    if n_plots > 0:\n",
    "        fig, axes = plt.subplots(2, max(2, n_plots//2 + n_plots%2), figsize=(16, 10))\n",
    "        axes = axes.flatten() if n_plots > 1 else [axes]\n",
    "        \n",
    "        plot_idx = 0\n",
    "        \n",
    "        # Plot precipitation relationships\n",
    "        for precip_col in precip_cols:\n",
    "            if plot_idx < len(axes):\n",
    "                # Scatter plot\n",
    "                sample_data = elevation_df.sample(n=min(10000, len(elevation_df)), random_state=RANDOM_STATE)\n",
    "                axes[plot_idx].scatter(sample_data[elev_col], sample_data[precip_col], \n",
    "                                     alpha=0.5, s=1)\n",
    "                axes[plot_idx].set_xlabel('Elevation (m)')\n",
    "                axes[plot_idx].set_ylabel('Precipitation (mm)')\n",
    "                axes[plot_idx].set_title(f'Elevation vs Precipitation\\n{precip_col}', fontweight='bold')\n",
    "                axes[plot_idx].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Calculate correlation\n",
    "                corr = elevation_df[[elev_col, precip_col]].corr().iloc[0, 1]\n",
    "                axes[plot_idx].text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                                   transform=axes[plot_idx].transAxes, \n",
    "                                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "                plot_idx += 1\n",
    "        \n",
    "        # Plot SWE relationships\n",
    "        for swe_col in swe_cols:\n",
    "            if plot_idx < len(axes):\n",
    "                # Scatter plot\n",
    "                sample_data = elevation_df.sample(n=min(10000, len(elevation_df)), random_state=RANDOM_STATE)\n",
    "                axes[plot_idx].scatter(sample_data[elev_col], sample_data[swe_col], \n",
    "                                     alpha=0.5, s=1, color='orange')\n",
    "                axes[plot_idx].set_xlabel('Elevation (m)')\n",
    "                axes[plot_idx].set_ylabel('SWE (mm)')\n",
    "                axes[plot_idx].set_title(f'Elevation vs SWE\\n{swe_col}', fontweight='bold')\n",
    "                axes[plot_idx].grid(True, alpha=0.3)\n",
    "                \n",
    "                # Calculate correlation\n",
    "                corr = elevation_df[[elev_col, swe_col]].corr().iloc[0, 1]\n",
    "                axes[plot_idx].text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                                   transform=axes[plot_idx].transAxes, \n",
    "                                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "                plot_idx += 1\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(plot_idx, len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_plots_dir / 'elevation_climate_relationships.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✅ Climate relationships saved to {output_plots_dir / 'elevation_climate_relationships.png'}\")\n",
    "    else:\n",
    "        print(\"❌ No climate variables found for analysis\")\n",
    "else:\n",
    "    print(\"❌ Cannot perform statistical analysis - missing required columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Summary\n",
    "\n",
    "This notebook provides comprehensive visualization and analysis of elevation data including:\n",
    "\n",
    "1. **Spatial Visualizations**:\n",
    "   - Elevation class polygons from shapefile\n",
    "   - Data point distribution from CSV using prioritized grid coordinates\n",
    "   - Combined spatial views\n",
    "\n",
    "2. **Statistical Analysis**:\n",
    "   - Correlation analysis between elevation and climate variables\n",
    "   - Distribution analysis by elevation bins\n",
    "\n",
    "3. **Coordinate Prioritization**:\n",
    "   - **Priority 1**: `grid_lon`, `grid_lat` (most accurate for spatial analysis)\n",
    "   - **Priority 2**: `original_lon`, `original_lat` (fallback coordinates)\n",
    "   - **Priority 3**: Flexible detection for other coordinate naming conventions\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Memory-efficient data loading** for large CSV files\n",
    "- **Prioritized coordinate selection** ensuring grid coordinates are used when available\n",
    "- **Robust error handling** for missing data or files\n",
    "- **Professional visualizations** with proper legends and annotations\n",
    "- **Modular design** allowing easy customization\n",
    "\n",
    "### Output Files Generated\n",
    "\n",
    "All visualizations are saved to the `data/output_plots/` directory:\n",
    "- `elevation_shapefile_overview.png` - Shapefile elevation classes\n",
    "- `data_point_distribution.png` - Spatial distribution using grid coordinates\n",
    "- `combined_elevation_points.png` - Combined spatial view\n",
    "- `elevation_climate_relationships.png` - Statistical relationships\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Enhanced Analysis**:\n",
    "   - Add temporal analysis if time data is available\n",
    "   - Include box plots by elevation bins\n",
    "   - Add 3D surface plots for multi-dimensional relationships\n",
    "\n",
    "2. **Data Quality**:\n",
    "   - Generate comprehensive summary statistics\n",
    "   - Create data quality reports\n",
    "   - Validate coordinate accuracy\n",
    "\n",
    "3. **Advanced Visualizations**:\n",
    "   - Interactive plots with plotly\n",
    "   - Seasonal pattern analysis\n",
    "   - Extreme event identification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
